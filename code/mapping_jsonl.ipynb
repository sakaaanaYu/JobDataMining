{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 技能部分结果映射"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 完成 llm 调用后输出结果的映射"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_files(batch_path, part_path): \n",
    "    \n",
    "    with open(batch_path, 'r', encoding = 'utf-8') as file1, open(part_path, 'r', encoding = 'utf-8') as file2:\n",
    "        data1 = [json.loads(line) for line in file1]\n",
    "        data2 = [json.loads(line) for line in file2]\n",
    "\n",
    "    df1 = pd.DataFrame(data1)\n",
    "    df2 = pd.DataFrame(data2)\n",
    "\n",
    "    print(\"Batch columns:\", df1.columns.tolist())\n",
    "    print(\"Part columns:\", df2.columns.tolist())\n",
    "\n",
    "    merged_df = pd.merge(df1, df2, on='custom_id', how='inner')\n",
    "    \n",
    "    if 'body' in merged_df.columns:\n",
    "        merged_df['parsed_body'] = merged_df['body'].apply(json.dumps) \n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_merged_dataframes(dataframes):\n",
    "    if not dataframes:\n",
    "        raise ValueError(\"The list of dataframes is empty!\")\n",
    "    \n",
    "    # 合并所有的 DataFrame\n",
    "    final_combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "    \n",
    "    return final_combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch columns: ['id', 'custom_id', 'response', 'error']\n",
      "Part columns: ['custom_id', 'method', 'url', 'body']\n",
      "Batch columns: ['id', 'custom_id', 'response', 'error']\n",
      "Part columns: ['custom_id', 'method', 'url', 'body']\n",
      "Batch columns: ['id', 'custom_id', 'response', 'error']\n",
      "Part columns: ['custom_id', 'method', 'url', 'body']\n",
      "Batch columns: ['id', 'custom_id', 'response']\n",
      "Part columns: ['custom_id', 'method', 'url', 'body']\n",
      "Batch columns: ['id', 'custom_id', 'response']\n",
      "Part columns: ['custom_id', 'method', 'url', 'body']\n",
      "Batch columns: ['id', 'custom_id', 'response']\n",
      "Part columns: ['custom_id', 'method', 'url', 'body']\n",
      "Batch columns: ['id', 'custom_id', 'response']\n",
      "Part columns: ['custom_id', 'method', 'url', 'body']\n",
      "Batch columns: ['id', 'custom_id', 'response', 'error']\n",
      "Part columns: ['custom_id', 'method', 'url', 'body']\n",
      "Batch columns: ['id', 'custom_id', 'response', 'error']\n",
      "Part columns: ['custom_id', 'method', 'url', 'body']\n"
     ]
    }
   ],
   "source": [
    "# 文件路径列表\n",
    "batch_files = [\n",
    "    \"..\\\\data\\\\cutwords\\\\req_to_skills_result\\\\batch_part1_output.jsonl\",\n",
    "    \"..\\\\data\\\\cutwords\\\\req_to_skills_result\\\\batch_part2_output.jsonl\",\n",
    "    \"..\\\\data\\\\cutwords\\\\req_to_skills_result\\\\batch_part3_output.jsonl\", \n",
    "    \"..\\\\data\\\\cutwords\\\\req_to_skills_result\\\\batch_part4_output.jsonl\", \n",
    "    \"..\\\\data\\\\cutwords\\\\req_to_skills_result\\\\batch_part5_output.jsonl\", \n",
    "    \"..\\\\data\\\\cutwords\\\\req_to_skills_result\\\\batch_part6_output.jsonl\", \n",
    "    \"..\\\\data\\\\cutwords\\\\req_to_skills_result\\\\batch_part7_output.jsonl\", \n",
    "    \"..\\\\data\\\\cutwords\\\\req_to_skills_result\\\\batch_part8_output.jsonl\", \n",
    "    \"..\\\\data\\\\cutwords\\\\req_to_skills_result\\\\batch_part9_output.jsonl\"\n",
    "]\n",
    "\n",
    "part_files = [\n",
    "    \"..\\\\data\\\\cutwords\\\\req_to_skills_result\\\\part1.jsonl\",\n",
    "    \"..\\\\data\\\\cutwords\\\\req_to_skills_result\\\\part2.jsonl\",\n",
    "    \"..\\\\data\\\\cutwords\\\\req_to_skills_result\\\\part3.jsonl\", \n",
    "    \"..\\\\data\\\\cutwords\\\\req_to_skills_result\\\\part4.jsonl\", \n",
    "    \"..\\\\data\\\\cutwords\\\\req_to_skills_result\\\\part5.jsonl\", \n",
    "    \"..\\\\data\\\\cutwords\\\\req_to_skills_result\\\\part6.jsonl\", \n",
    "    \"..\\\\data\\\\cutwords\\\\req_to_skills_result\\\\part7.jsonl\", \n",
    "    \"..\\\\data\\\\cutwords\\\\req_to_skills_result\\\\part8.jsonl\", \n",
    "    \"..\\\\data\\\\cutwords\\\\req_to_skills_result\\\\part9.jsonl\"\n",
    "]\n",
    "\n",
    "if len(batch_files) != len(part_files):\n",
    "    raise ValueError(\"The number of batch files and part files must match!\")\n",
    "\n",
    "merged_dfs = [mapping_files(batch, part) for batch, part in zip(batch_files, part_files)]\n",
    "final_merged_df = combine_merged_dataframes(merged_dfs)\n",
    "\n",
    "final_merged_df.to_json('..\\\\data\\\\cutwords\\\\req_to_skills_result\\\\final_merged.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 完成结果与招聘信息 id 的映射"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged_file = \"..\\\\data\\\\cutwords\\\\req_to_skills_result\\\\final_merged.jsonl\"\n",
    "jobdata_with_id = \"..\\\\data\\\\jobdata_preprocessed_with_id.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理 jsonl\n",
    "content_data = []\n",
    "\n",
    "with open(final_merged_file, 'r', encoding='utf-8') as file:\n",
    "    for line_number, line in enumerate(file, 1):\n",
    "        try:\n",
    "            record = json.loads(line)\n",
    "            \n",
    "            # 检查 'custom_id' 和 'response' 是否存在\n",
    "            if 'custom_id' in record and 'response' in record:\n",
    "                response_body = record['response'].get('body', {})\n",
    "                choices = response_body.get('choices', [])\n",
    "                \n",
    "                if choices:  # 确保 choices 存在且非空\n",
    "                    message = choices[0].get('message', {})\n",
    "                    content = message.get('content', '')\n",
    "\n",
    "                    if content:  # 确保 content 存在\n",
    "                        try:\n",
    "                            decoded_content = json.loads(content) \n",
    "                            content_data.append({\n",
    "                                'custom_id': record['custom_id'],\n",
    "                                'hard_skills': decoded_content.get('hard_skills', []),\n",
    "                                'soft_skills': decoded_content.get('soft_skills', [])\n",
    "                            })\n",
    "                        except json.JSONDecodeError as e:\n",
    "                            print(f\"JSONDecodeError at line {line_number}: {e}\")\n",
    "                    else:\n",
    "                        print(f\"No content found in message for custom_id: {record['custom_id']} (line {line_number})\")\n",
    "                else:\n",
    "                    print(f\"No choices found in body for custom_id: {record['custom_id']} (line {line_number})\")\n",
    "            else:\n",
    "                print(f\"Missing 'custom_id' or 'response' at line {line_number}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error at line {line_number}: {e}\")\n",
    "\n",
    "final_content_df = pd.DataFrame(content_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               custom_id               hard_skills         soft_skills\n",
      "0  Lcer-s-mfC1_DTn4Xhi8B  [媒体运营, 视觉设计, 数据处理, 内容策略]        [组织技能, 交际能力]\n",
      "1  j2iMOLV8nyaPmi7N4i7vW              [媒体运营, 数据处理]  [个人素养, 交际能力, 市场管理]\n",
      "2  avZPqlcVKpPDNHyTPUeQd              [媒体运营, 数据处理]        [组织技能, 交际能力]\n",
      "3  GsSA5fS_1ur0eWLbv0Pgl        [数据处理, 内容策略, 媒体运营]              [市场管理]\n",
      "4  MWp8dcg3q2v49IP6jqWlM              [媒体运营, 数据处理]  [个人素养, 抗压能力, 交际能力]\n"
     ]
    }
   ],
   "source": [
    "print(final_content_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame columns: Index(['岗位编号', '岗位名称', '工作类型', '工作经验', '城市', '行政区域', '街道区域', '企业名称', '企业标签',\n",
      "       '企业人数规模', '学历', '融资阶段', '工作简介', '企业财产类型', '招聘信息更新时间', '招募人数', '岗位标签',\n",
      "       '岗位分类', 'salary_min', 'salary_max', 'salary_type', 'custom_id',\n",
      "       'hard_skills_jobdata', 'soft_skills_jobdata', 'hard_skills_final',\n",
      "       'soft_skills_final'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "jobdata_df = pd.read_csv(jobdata_with_id)\n",
    "\n",
    "# 确保 ID 对应一致\n",
    "if 'id' in jobdata_df.columns:\n",
    "    jobdata_df.rename(columns={'id': 'custom_id'}, inplace=True)\n",
    "\n",
    "# 添加空列\n",
    "jobdata_df['hard_skills'] = None\n",
    "jobdata_df['soft_skills'] = None\n",
    "\n",
    "# 合并数据\n",
    "merged_df = jobdata_df.merge(final_content_df, on='custom_id', how='inner', suffixes=('_jobdata', '_final'))\n",
    "\n",
    "print(\"Merged DataFrame columns:\", merged_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after renaming and cleaning: Index(['岗位编号', '岗位名称', '工作类型', '工作经验', '城市', '行政区域', '街道区域', '企业名称', '企业标签',\n",
      "       '企业人数规模', '学历', '融资阶段', '工作简介', '企业财产类型', '招聘信息更新时间', '招募人数', '岗位标签',\n",
      "       '岗位分类', 'salary_min', 'salary_max', 'salary_type', 'custom_id',\n",
      "       'hard_skills', 'soft_skills'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 发现 `hard_skills` 和 `soft_skills` 被重命名，故修正列名\n",
    "if 'hard_skills_final' in merged_df.columns:\n",
    "    merged_df.rename(columns={\n",
    "        'hard_skills_final': 'hard_skills',\n",
    "        'soft_skills_final': 'soft_skills'\n",
    "    }, inplace=True)\n",
    "\n",
    "merged_df.drop(columns=['hard_skills_jobdata', 'soft_skills_jobdata'], inplace=True, errors='ignore')\n",
    "print(\"Columns after renaming and cleaning:\", merged_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      岗位编号         岗位名称 工作类型   工作经验  城市 行政区域 街道区域  \\\n",
      "0  CC120994460J40664011302       天猫运营店长   全职   3-5年  北京   西城   椿树   \n",
      "1  CC447718930J40602358006    天猫运营经理/店长   全职   3-5年  北京   朝阳  麦子店   \n",
      "2  CC130850440J40657947102       天猫运营助理   全职   经验不限  北京   海淀  西北旺   \n",
      "3  CC513268080J40826412204       天猫运营店长   全职   1-3年  北京   海淀   东升   \n",
      "4  CC447718930J40602828706  天猫运营经理/天猫店长   全职  5-10年  北京   朝阳  麦子店   \n",
      "\n",
      "             企业名称 企业标签    企业人数规模  ...             招聘信息更新时间 招募人数  \\\n",
      "0  北京市美顺雅鞋业有限责任公司  NaN  500-999人  ...  2024-11-15 10:26:26    1   \n",
      "1         克拉斯国际家居  NaN  500-999人  ...  2024-11-15 00:19:43    1   \n",
      "2    北京绿伞科技股份有限公司  NaN  500-999人  ...  2024-11-14 16:44:33    1   \n",
      "3  北京意间文化艺术发展有限公司  NaN    20-99人  ...  2024-11-13 16:34:52    1   \n",
      "4         克拉斯国际家居  NaN  500-999人  ...  2024-11-15 00:05:03    1   \n",
      "\n",
      "                       岗位标签     岗位分类 salary_min  salary_max salary_type  \\\n",
      "0                 天猫;淘宝;服装;  淘宝/天猫运营      96000      144000           M   \n",
      "1     天猫;淘宝;家具;店长;经理;新媒体运营;  淘宝/天猫运营     120000      167999           M   \n",
      "2                 淘宝;日化;助理;  淘宝/天猫运营      84000      120000           M   \n",
      "3              天猫;淘宝;饰品;店长;  淘宝/天猫运营      96000      120000           M   \n",
      "4  淘宝/天猫;京东;抖音小店;天猫推广;付费推广;  电商经理/主管     120000      144000           M   \n",
      "\n",
      "               custom_id               hard_skills         soft_skills  \n",
      "0  Lcer-s-mfC1_DTn4Xhi8B  [媒体运营, 视觉设计, 数据处理, 内容策略]        [组织技能, 交际能力]  \n",
      "1  j2iMOLV8nyaPmi7N4i7vW              [媒体运营, 数据处理]  [个人素养, 交际能力, 市场管理]  \n",
      "2  avZPqlcVKpPDNHyTPUeQd              [媒体运营, 数据处理]        [组织技能, 交际能力]  \n",
      "3  GsSA5fS_1ur0eWLbv0Pgl        [数据处理, 内容策略, 媒体运营]              [市场管理]  \n",
      "4  MWp8dcg3q2v49IP6jqWlM              [媒体运营, 数据处理]  [个人素养, 抗压能力, 交际能力]  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "processed_df = merged_df.dropna(subset=['hard_skills', 'soft_skills'])\n",
    "print(processed_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df.to_csv('..\\\\data\\\\task3\\\\jobdata_get_skills.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 态度 -> 观点部分映射处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch columns: ['id', 'custom_id', 'response', 'error']\n",
      "Part columns: ['custom_id', 'method', 'url', 'body']\n",
      "Batch columns: ['id', 'custom_id', 'response', 'error']\n",
      "Part columns: ['custom_id', 'method', 'url', 'body']\n"
     ]
    }
   ],
   "source": [
    "# 文件路径列表\n",
    "batch_files = [\n",
    "    \"..\\\\data\\\\task4\\\\batch_part1_output.jsonl\",\n",
    "    \"..\\\\data\\\\task4\\\\batch_part1_output.jsonl\"\n",
    "]\n",
    "\n",
    "part_files = [\n",
    "    \"..\\\\data\\\\task4\\\\part1.jsonl\",\n",
    "    \"..\\\\data\\\\task4\\\\part2.jsonl\"\n",
    "]\n",
    "\n",
    "if len(batch_files) != len(part_files):\n",
    "    raise ValueError(\"The number of batch files and part files must match!\")\n",
    "\n",
    "merged_dfs = [mapping_files(batch, part) for batch, part in zip(batch_files, part_files)]\n",
    "final_merged_df = combine_merged_dataframes(merged_dfs)\n",
    "\n",
    "final_merged_df.to_json('..\\\\data\\\\task4\\\\merged_opinions.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged_file = \"..\\\\data\\\\task4\\\\merged_opinions.jsonl\"\n",
    "zhihudata_with_id = \"..\\\\data\\\\attitudes_zhihu_with_ids.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custom_id</th>\n",
       "      <th>agree</th>\n",
       "      <th>disagree</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AkDAFULrD7GTJdWvSE8TN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[journalism-favors-new-media-jobs, tier-1-citi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sViYNRTOSjTcxXPEL2ykH</td>\n",
       "      <td>[journalism-favors-new-media-jobs, experience-...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[tier-1-cities-offer-more-jobs, education-leve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aD9e51cniLKXotH1AyMZ2</td>\n",
       "      <td>[]</td>\n",
       "      <td>[journalism-favors-new-media-jobs, tier-1-citi...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3S51njyrremig0DMNLY-S</td>\n",
       "      <td>[journalism-favors-new-media-jobs]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[tier-1-cities-offer-more-jobs, experience-mat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r4ro9pzQ9xvmrlj0wIuMn</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[journalism-favors-new-media-jobs, tier-1-citi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               custom_id                                              agree  \\\n",
       "0  AkDAFULrD7GTJdWvSE8TN                                                 []   \n",
       "1  sViYNRTOSjTcxXPEL2ykH  [journalism-favors-new-media-jobs, experience-...   \n",
       "2  aD9e51cniLKXotH1AyMZ2                                                 []   \n",
       "3  3S51njyrremig0DMNLY-S                 [journalism-favors-new-media-jobs]   \n",
       "4  r4ro9pzQ9xvmrlj0wIuMn                                                 []   \n",
       "\n",
       "                                            disagree  \\\n",
       "0                                                 []   \n",
       "1                                                 []   \n",
       "2  [journalism-favors-new-media-jobs, tier-1-citi...   \n",
       "3                                                 []   \n",
       "4                                                 []   \n",
       "\n",
       "                                             neutral  \n",
       "0  [journalism-favors-new-media-jobs, tier-1-citi...  \n",
       "1  [tier-1-cities-offer-more-jobs, education-leve...  \n",
       "2                                                 []  \n",
       "3  [tier-1-cities-offer-more-jobs, experience-mat...  \n",
       "4  [journalism-favors-new-media-jobs, tier-1-citi...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_data = []\n",
    "\n",
    "with open(final_merged_file, 'r', encoding='utf-8') as file:\n",
    "    for line_number, line in enumerate(file, 1):\n",
    "        try:\n",
    "            record = json.loads(line)\n",
    "            \n",
    "            # 检查 'custom_id' 和 'response' 是否存在\n",
    "            if 'custom_id' in record and 'response' in record:\n",
    "                response_body = record['response'].get('body', {})\n",
    "                choices = response_body.get('choices', [])\n",
    "        \n",
    "                if choices:  # 确保 choices 存在且非空\n",
    "                    message = choices[0].get('message', {})\n",
    "                    content = message.get('content', '')\n",
    "\n",
    "                    if content:  # 确保 content 存在\n",
    "                        try:\n",
    "                            decoded_content = json.loads(content) \n",
    "                            content_data.append({\n",
    "                                'custom_id': record['custom_id'],\n",
    "                                'agree': decoded_content.get('agree', []),\n",
    "                                'disagree': decoded_content.get('disagree', []), \n",
    "                                'neutral': decoded_content.get('neutral', [])\n",
    "                            })\n",
    "                        except json.JSONDecodeError as e:\n",
    "                            print(f\"JSONDecodeError at line {line_number}: {e}\")\n",
    "                    else:\n",
    "                        print(f\"No content found in message for custom_id: {record['custom_id']} (line {line_number})\")\n",
    "                else:\n",
    "                    print(f\"No choices found in body for custom_id: {record['custom_id']} (line {line_number})\")\n",
    "            else:\n",
    "                print(f\"Missing 'custom_id' or 'response' at line {line_number}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error at line {line_number}: {e}\")\n",
    "\n",
    "final_content_df = pd.DataFrame(content_data)\n",
    "\n",
    "final_content_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after renaming and cleaning: Index(['custom_id', 'content', 'agree', 'disagree', 'neutral'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "zhihudata_df = pd.read_csv(zhihudata_with_id)\n",
    "\n",
    "# 确保 ID 对应一致\n",
    "if 'id' in zhihudata_df.columns:\n",
    "    zhihudata_df.rename(columns={'id': 'custom_id'}, inplace=True)\n",
    "\n",
    "# 添加空列\n",
    "zhihudata_df['agree'] = None\n",
    "zhihudata_df['disagree'] = None\n",
    "zhihudata_df['neutral'] = None\n",
    "\n",
    "# 合并数据\n",
    "merged_df = zhihudata_df.merge(final_content_df, on='custom_id', how='inner', suffixes=('_zhihudata', '_final'))\n",
    "\n",
    "if 'agree_final' in merged_df.columns:\n",
    "    merged_df.rename(columns={\n",
    "        'agree_final': 'agree',\n",
    "        'disagree_final': 'disagree',\n",
    "        'neutral_final' : 'neutral'\n",
    "    }, inplace=True)\n",
    "\n",
    "merged_df.drop(columns=['agree_zhihudata', 'disagree_zhihudata', 'neutral_zhihudata'], inplace=True, errors='ignore')\n",
    "print(\"Columns after renaming and cleaning:\", merged_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custom_id</th>\n",
       "      <th>content</th>\n",
       "      <th>agree</th>\n",
       "      <th>disagree</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AkDAFULrD7GTJdWvSE8TN</td>\n",
       "      <td>报纸 科技媒体 互联网</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[journalism-favors-new-media-jobs, tier-1-citi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sViYNRTOSjTcxXPEL2ykH</td>\n",
       "      <td>知乎的神奇之处在于，会帮你记录来时的路时间来到了2024，距离第二次回答也已经3年，真弹指一...</td>\n",
       "      <td>[journalism-favors-new-media-jobs, experience-...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[tier-1-cities-offer-more-jobs, education-leve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aD9e51cniLKXotH1AyMZ2</td>\n",
       "      <td>21年毕业的，这几天面临失业危机了，想找几个同学问问他们的现状，了解一下新闻学的就业行情。当...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[journalism-favors-new-media-jobs, tier-1-citi...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3S51njyrremig0DMNLY-S</td>\n",
       "      <td>目前刚被录取，还没入学军训我知道社会对新闻学的评价哈哈哈哈哈被调剂来的，是命运让我来到这里～...</td>\n",
       "      <td>[journalism-favors-new-media-jobs]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[tier-1-cities-offer-more-jobs, experience-mat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r4ro9pzQ9xvmrlj0wIuMn</td>\n",
       "      <td>啊啊啊啊，我也蹲一个。四年后毕业。</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[journalism-favors-new-media-jobs, tier-1-citi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               custom_id                                            content  \\\n",
       "0  AkDAFULrD7GTJdWvSE8TN                                        报纸 科技媒体 互联网   \n",
       "1  sViYNRTOSjTcxXPEL2ykH  知乎的神奇之处在于，会帮你记录来时的路时间来到了2024，距离第二次回答也已经3年，真弹指一...   \n",
       "2  aD9e51cniLKXotH1AyMZ2  21年毕业的，这几天面临失业危机了，想找几个同学问问他们的现状，了解一下新闻学的就业行情。当...   \n",
       "3  3S51njyrremig0DMNLY-S  目前刚被录取，还没入学军训我知道社会对新闻学的评价哈哈哈哈哈被调剂来的，是命运让我来到这里～...   \n",
       "4  r4ro9pzQ9xvmrlj0wIuMn                                  啊啊啊啊，我也蹲一个。四年后毕业。   \n",
       "\n",
       "                                               agree  \\\n",
       "0                                                 []   \n",
       "1  [journalism-favors-new-media-jobs, experience-...   \n",
       "2                                                 []   \n",
       "3                 [journalism-favors-new-media-jobs]   \n",
       "4                                                 []   \n",
       "\n",
       "                                            disagree  \\\n",
       "0                                                 []   \n",
       "1                                                 []   \n",
       "2  [journalism-favors-new-media-jobs, tier-1-citi...   \n",
       "3                                                 []   \n",
       "4                                                 []   \n",
       "\n",
       "                                             neutral  \n",
       "0  [journalism-favors-new-media-jobs, tier-1-citi...  \n",
       "1  [tier-1-cities-offer-more-jobs, education-leve...  \n",
       "2                                                 []  \n",
       "3  [tier-1-cities-offer-more-jobs, experience-mat...  \n",
       "4  [journalism-favors-new-media-jobs, tier-1-citi...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df = merged_df.dropna(subset=['agree', 'disagree', 'neutral'])\n",
    "processed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df.to_csv(\"..\\\\data\\\\task4\\\\zhihu_get_opinion.csv\", index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
